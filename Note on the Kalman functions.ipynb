{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A short description on the design of the Kalman functions to build your own dynamic linear model\n",
    "\n",
    "- library Kalman_LLT for the local linear trend model\n",
    "\n",
    "- library Kalman_RW for the random walk model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The libraries are composed of 3 functions.\n",
    "\n",
    "Exemple Kalman_LLT library:\n",
    "\n",
    "- Kalman_LLT function that is called to estimate the model\n",
    "- ml_FWD function: runs the Kalman filter with the optimized parameters\n",
    "- Kalman Filter: runs the Kalman filter and estimate the log-likelyhood function \n",
    "\n",
    "The model has to be designed in the Kalman_LLT and in the ml_FWD functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Kalman_LLT(Y,X,sr1,sr2)\n",
    "\n",
    "Input parameters\n",
    "\n",
    "- Y: the measurement\n",
    "- X: explanatory factors\n",
    "- sr1, sr2: the signal to noise ratios\n",
    "\n",
    "Output:\n",
    "\n",
    "- filtered states (spread and slope)\n",
    "- smoothed states (spread and slope)\n",
    "\n",
    "Model design:\n",
    "\n",
    "- nZ: number of states / explanatory factors\n",
    "- param: vector containing the parameters to be estimated\n",
    "- A: transition matrix\n",
    "- Q: covariance matrix of the state innovation error s\n",
    "- H: covariance matrix\n",
    "- X0: initial state vector\n",
    "- P0: initial state covariance matrix. Diagonal.\n",
    "\n",
    "The parameters to be estimated are:\n",
    "- the initial state values in X0\n",
    "- the initial state covariance matrix on the diagonal of P0\n",
    "- the variance of the measurement error in H\n",
    "\n",
    "Note, to optimize the convergence of the optimization algorythm (BFGS), the variance parameters are expressed as exp(param), with insure the positivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kalman_LLT(y,z,sr1,sr2):\n",
    "    global _Q, _H, _Y, _Z, _X0, _P0, _A, _nZ, _sr1, _sr2\n",
    "    Y=y\n",
    "    Z=z\n",
    "    nZ=len(Z.T)\n",
    "    param=np.ones((4+1))\n",
    "    #INITIAL STATES\n",
    "    X0=np.zeros((nZ,1))\n",
    "    #INITIAL STATE COVARIANCE\n",
    "    P0=np.eye(nZ)*10**6\n",
    "    #TRANSITION MATRIX\n",
    "    A=np.eye(nZ)\n",
    "    A[0,1]=1\n",
    "    #STATE INNOVATION COVARIANCE MATRIX\n",
    "    Q=np.zeros((nZ,nZ))  \n",
    "    #SIGNAL COVARIANCE MATRIX\n",
    "    H=np.zeros((1,1))    \n",
    "    #GLOBAL PARAMETERS\n",
    "    _Q=Q; _H=H; _Y=Y; _Z=Z; _X0=X0; _P0=P0; _A=A; _nZ=nZ; _sr1=sr1; _sr2=sr2\n",
    "    # OPTIMIZATION\n",
    "    out_opt=sp.optimize.minimize(ml_FWD,param,method='BFGS', tol=0.001)\n",
    "    param=out_opt['x']\n",
    "    print(out_opt['success'])\n",
    "    #ESTIMATION WITH OPTIMIZED PARAMETERS\n",
    "    param=param.reshape(max(param.shape))\n",
    "    H=np.exp(param[0])\n",
    "    X0=param[1:3]\n",
    "    Q[0,0]=sr1*H\n",
    "    Q[1,1]=sr2*H\n",
    "    P0[0,0]=np.exp(param[3])\n",
    "    P0[1,1]=np.exp(param[4])\n",
    "    (likely,XOUT,POUT,XSOUT)=kalman_filter(_Y,_Z,X0,P0,A,Q,H)   \n",
    "    return XOUT, XSOUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ml_FWD(param)\n",
    "\n",
    "Input parameters\n",
    "\n",
    "- param: the parameter vector to be estimated\n",
    "\n",
    "Output:\n",
    "\n",
    "- the log-likelyhood function\n",
    "\n",
    "Model design: define the global matrices/verctors/variables that contain the parameters to be estimated.\n",
    "\n",
    "In this model:\n",
    "\n",
    "- _A: transition matrix\n",
    "- _Q: covariance matrix of the state innovation error s\n",
    "- _H: covariance matrix\n",
    "- _X0: initial state vector\n",
    "- _P0: initial state covariance matrix. Diagonal.\n",
    "\n",
    "Note, to optimize the convergence of the optimization algorythm (BFGS), the variance parameters are expressed as exp(param), with insure the positivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_FWD(param):\n",
    "    param=param.reshape(max(param.shape))\n",
    "    _H=np.exp(param[0])\n",
    "    _X0=param[1:3]\n",
    "    _Q[0,0]=_sr1*_H\n",
    "    _Q[1,1]=_sr2*_H\n",
    "    _P0[0,0]=np.exp(param[3])\n",
    "    _P0[1,1]=np.exp(param[4])\n",
    "    (likely,XOUT,POUT,XSOUT)=kalman_filter(_Y,_Z,_X0,_P0,_A,_Q,_H)\n",
    "    return -likely\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Kalman_filter(Y,Z,X0,P0,A,Q,H)\n",
    "\n",
    "Input parameters\n",
    "\n",
    "- (Y,Z,X0,P0,A,Q,H) described above\n",
    "\n",
    "Output:\n",
    "\n",
    "- log-likelyhood funtion: likely/T\n",
    "- filtered state vectors: Xout\n",
    "- state covariance matrix: Pout\n",
    "- smoothed states vectors: XoutS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_filter(Y,Z,X0,P0,A,Q,H):\n",
    "    #Y(T,1) Z(T,nZ) X0(nZ) P0(nZ,nZ) A(nZ,nZ) Q(nZ,nZ) H(1)   \n",
    "    nZ=len(Z.T)\n",
    "    nT=len(Y)\n",
    "    #FOR FILTER\n",
    "    Zt=np.zeros((1,nZ))\n",
    "    Xout=np.zeros((nT,nZ))\n",
    "    Pout=np.zeros((nT,nZ,nZ))\n",
    "    #FOR SMOOTHER\n",
    "    XoutS=np.zeros((nT,nZ))\n",
    "    XtS=np.zeros((nT,nZ))\n",
    "    Pt1t=np.zeros((nT,nZ,nZ))\n",
    "    Ptt=np.zeros((nT,nZ,nZ))\n",
    "    Xtt=np.zeros((nT,nZ))\n",
    "    Xt1t=np.zeros((nT,nZ))\n",
    "    #FILTER\n",
    "    l1=0.0\n",
    "    l2=0.0\n",
    "    likely=0.0\n",
    "    Xt=X0\n",
    "    Pt=P0\n",
    "    #FILTER\n",
    "    for t in range(0,nT,1):\n",
    "        #estimation step\n",
    "        Xte=A.dot(Xt)\n",
    "        Pte=A.dot(Pt).dot(A.T)+Q            \n",
    "        #update\n",
    "        Zt[:,:]=Z[t,:]\n",
    "        vt=Y[t]-Zt.dot(Xte)\n",
    "        Ft=Zt.dot(Pte).dot(Zt.T)+H\n",
    "        if np.linalg.det(Ft)==0:\n",
    "            Ft=Ft+np.random.normal(0,10**-5,Ft.shape)\n",
    "        Fti=np.linalg.inv(Ft)\n",
    "        Xt=Xte+Pte.dot(Zt.T).dot(Fti).dot(vt)\n",
    "        Pt=(np.eye(nZ)-Pte.dot(Zt.T).dot(Fti).dot(Zt)).dot(Pte)\n",
    "        #stockage\n",
    "        Xout[t,:]=Xt.T\n",
    "        Pout[t,:,:]=Pt\n",
    "        l1=l1+np.log(np.linalg.det(Ft))\n",
    "        l2=l2+(vt.T).dot(Fti).dot(vt)\n",
    "        #pour smoother\n",
    "        Ptt[t,:,:]=Pt\n",
    "        Xtt[t,:]=Xt.T\n",
    "        Pt1t[t,:,:]=Pte\n",
    "        Xt1t[t,:]=Xte.T\n",
    "    likely=-0.5*nT*np.log(2*math.pi)-0.5*l1-0.5*l2\n",
    "    #SMOOTHER\n",
    "    XtS[nT-1,:]=Xtt[nT-1,:]\n",
    "    XoutS[nT-1,:]=Xtt[nT-1,:]\n",
    "    for t in range(nT-2,-1,-1):\n",
    "        if abs(np.linalg.det(Pt1t[t+1,:,:]))==0:\n",
    "            Pt1t[t+1,:,:]=Pt1t[t+1,:,:]+np.random.normal(0,10**-5,Pt1t[t+1,:,:].shape)\n",
    "        inverse=np.linalg.inv(Pt1t[t+1,:,:])\n",
    "        Ft=Ptt[t,:,:].dot(A.T).dot(inverse)\n",
    "        XtS[t,:]=Xtt[t,:]+Ft.dot(XtS[t+1,:]-Xt1t[t+1,:])\n",
    "        XoutS[t,:]=XtS[t,:]\n",
    "    likely=np.reshape(likely,(1))\n",
    "    return likely/nT,Xout,Pout,XoutS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
